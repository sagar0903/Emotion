{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df=pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val,'float32'))\n",
    "            train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val,'float32'))\n",
    "            test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "449/449 [==============================] - 344s 767ms/step - loss: 1.7267 - accuracy: 0.2882 - val_loss: 1.5544 - val_accuracy: 0.3828\n",
      "Epoch 2/30\n",
      "449/449 [==============================] - 493s 1s/step - loss: 1.5187 - accuracy: 0.4022 - val_loss: 1.3962 - val_accuracy: 0.4614\n",
      "Epoch 3/30\n",
      "449/449 [==============================] - 499s 1s/step - loss: 1.4110 - accuracy: 0.4549 - val_loss: 1.3422 - val_accuracy: 0.4745\n",
      "Epoch 4/30\n",
      "449/449 [==============================] - 519s 1s/step - loss: 1.3466 - accuracy: 0.4820 - val_loss: 1.2991 - val_accuracy: 0.4946\n",
      "Epoch 5/30\n",
      "449/449 [==============================] - 525s 1s/step - loss: 1.3020 - accuracy: 0.5011 - val_loss: 1.2814 - val_accuracy: 0.5065\n",
      "Epoch 6/30\n",
      "449/449 [==============================] - 505s 1s/step - loss: 1.2689 - accuracy: 0.5104 - val_loss: 1.2321 - val_accuracy: 0.5222\n",
      "Epoch 7/30\n",
      "449/449 [==============================] - 521s 1s/step - loss: 1.2323 - accuracy: 0.5290 - val_loss: 1.2249 - val_accuracy: 0.5344\n",
      "Epoch 8/30\n",
      "449/449 [==============================] - 526s 1s/step - loss: 1.2074 - accuracy: 0.5386 - val_loss: 1.2174 - val_accuracy: 0.5280\n",
      "Epoch 9/30\n",
      "449/449 [==============================] - 353s 785ms/step - loss: 1.1847 - accuracy: 0.5481 - val_loss: 1.1922 - val_accuracy: 0.5433\n",
      "Epoch 10/30\n",
      "449/449 [==============================] - 333s 742ms/step - loss: 1.1616 - accuracy: 0.5553 - val_loss: 1.1902 - val_accuracy: 0.5408\n",
      "Epoch 11/30\n",
      "449/449 [==============================] - 338s 754ms/step - loss: 1.1410 - accuracy: 0.5642 - val_loss: 1.1824 - val_accuracy: 0.5458\n",
      "Epoch 12/30\n",
      "449/449 [==============================] - 338s 754ms/step - loss: 1.1220 - accuracy: 0.5725 - val_loss: 1.1665 - val_accuracy: 0.5497\n",
      "Epoch 13/30\n",
      "449/449 [==============================] - 333s 741ms/step - loss: 1.1044 - accuracy: 0.5763 - val_loss: 1.1579 - val_accuracy: 0.5567\n",
      "Epoch 14/30\n",
      "449/449 [==============================] - 332s 740ms/step - loss: 1.0813 - accuracy: 0.5879 - val_loss: 1.1531 - val_accuracy: 0.5542\n",
      "Epoch 15/30\n",
      "449/449 [==============================] - 303s 675ms/step - loss: 1.0684 - accuracy: 0.5885 - val_loss: 1.1610 - val_accuracy: 0.5567\n",
      "Epoch 16/30\n",
      "449/449 [==============================] - 272s 606ms/step - loss: 1.0522 - accuracy: 0.6019 - val_loss: 1.1648 - val_accuracy: 0.5628\n",
      "Epoch 17/30\n",
      "449/449 [==============================] - 236s 525ms/step - loss: 1.0368 - accuracy: 0.6043 - val_loss: 1.1516 - val_accuracy: 0.5690\n",
      "Epoch 18/30\n",
      "449/449 [==============================] - 236s 525ms/step - loss: 1.0216 - accuracy: 0.6074 - val_loss: 1.1690 - val_accuracy: 0.5506\n",
      "Epoch 19/30\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.9975 - accuracy: 0.6216 - val_loss: 1.1519 - val_accuracy: 0.5676\n",
      "Epoch 20/30\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.9882 - accuracy: 0.6221 - val_loss: 1.1554 - val_accuracy: 0.5690\n",
      "Epoch 21/30\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.9666 - accuracy: 0.6315 - val_loss: 1.1777 - val_accuracy: 0.5628\n",
      "Epoch 22/30\n",
      "449/449 [==============================] - 235s 523ms/step - loss: 0.9562 - accuracy: 0.6363 - val_loss: 1.1649 - val_accuracy: 0.5684\n",
      "Epoch 23/30\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.9323 - accuracy: 0.6430 - val_loss: 1.1730 - val_accuracy: 0.5748\n",
      "Epoch 24/30\n",
      "449/449 [==============================] - 245s 545ms/step - loss: 0.9225 - accuracy: 0.6488 - val_loss: 1.1719 - val_accuracy: 0.5684\n",
      "Epoch 25/30\n",
      "449/449 [==============================] - 279s 621ms/step - loss: 0.9178 - accuracy: 0.6551 - val_loss: 1.1835 - val_accuracy: 0.5787\n",
      "Epoch 26/30\n",
      "449/449 [==============================] - 157s 349ms/step - loss: 0.8914 - accuracy: 0.6617 - val_loss: 1.1911 - val_accuracy: 0.5723\n",
      "Epoch 27/30\n",
      "449/449 [==============================] - 157s 349ms/step - loss: 0.8837 - accuracy: 0.6651 - val_loss: 1.2304 - val_accuracy: 0.5698\n",
      "Epoch 28/30\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.8798 - accuracy: 0.6675 - val_loss: 1.1955 - val_accuracy: 0.5779\n",
      "Epoch 29/30\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.8600 - accuracy: 0.6714 - val_loss: 1.1959 - val_accuracy: 0.5684\n",
      "Epoch 30/30\n",
      "449/449 [==============================] - 170s 380ms/step - loss: 0.8367 - accuracy: 0.6847 - val_loss: 1.2395 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18b0645e8e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "\n",
    "model.load_weights('fer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,test_img=cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        \n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
